+++
chapter = 3
title = '生知能と人工(生)知能'
+++

前章では、生知能の概念セットは他者からの概念の寄せ集めであることを説明しました。
そのように考えると、私たちがどのように世界を解釈し行動を決定しているかは
生知能のネットワークの構造に大きく影響されていることが分かります。  
本章では、前章で説明した生知能のネットワークに人工知能が加わることによる影響を考えます。

前章で定義した用語を引き続き使用しますので、
必要に応じて確認しながら読み進めてください。

# メディアとしての人工知能
ひとつの人工知能は非常に多くの生知能とつながることができ、
高い頻度で生活に入り込んだ形でコミュニケーションをとることができます。
つまり生知能のネットワークは中心を持たない構造から、
人工知能を中心とした構造へと変化すると考えられます。

{{< figure
place="center"
src="images/ai_network.webp"
caption="生知能のネットワークに人工知能を加える"
>}}

この変化は何をもたらすのでしょうか？　
人工知能によって、より広範な他者の概念を取り入れることができれば、
自己の形成はより進むと考えられます。
一方で外部からのインプットが文化への適応に使われるだけならば、
人々の画一化をもたらすことになります。

これまでの人類の歴史を振り返ると、
ブロードキャストするメディアは本からラジオ、テレビ、インターネットと発展してきました。
現在SNSの普及は個人が非常に多くの人たちへの発信を可能にし、
また広範な人たちの情報を受け取れるようになりました。
人工知能はその延長線上に位置づけることができます。
連続的な変化として捉えることで未来予測の補助線が浮かんできます。  
このような観点から、まず過去のテクノロジーの発展が私達にどのような影響を与えたかを振り返りながら、人工知能がいる社会を予測します。

# AIは労働を奪うか
1930年、経済学者のジョン・メイナード・ケインズは"Economic Possibilities for our Grandchildren"の中で、技術進歩と資本の蓄積によって、あと100年くらいあれば経済問題の解決は可能であり、労働から解放された未来を予測しています。
2024年現在、技術の進歩と資本の蓄積の予測は的中しましたが、残念ながら経済問題はより深刻になる一方で、あと6年で解決に向かいそうな気配はありません。

「AIが労働を奪うか」という問いはしばしば取り上げられますが、
「理論的に可能」や「技術的に可能」だとしても、
それが理想的に使われるわけではありません。
人類はその過ちを何度も犯し続けています。
テクノロジーは人々の欲しい結論を提供し、その現実との乖離が人々を苦しめてきました。

先のケインズの予測は理論的可能性の提示であって、
同文書が中心的に記述していることは、それに対する懸念です。

> Will this be a benefit? If one believes at all in the real values of life, the prospect at least opens up the possibility of benefit. Yet I think with dread of the readjustment of the habits and instincts of the ordinary man, bred into him for countless generations, which he may be asked to discard within a few decades.  
これは有益なのだろうか？　
もし人生の真の価値を信じる者なら、恩恵がもたらされる可能性はあるように見通せるだろう。
とはいえ、
何世代にもわたって培われてきた習慣や本能を数十年のうちに捨て去ることが
一般庶民に要求されることを想像すると私は恐怖を感じる。
<cite>J.ケインズ "Economic Possibilities for our Grandchildren"より</cite>

つまり環境の変化に合わせて人々の慣習も変わる必要があります。
前章で定義した用語でいうと、
これまでの文化を一変し、新しい概念に適応される状況が必要です。
既存の文化に適応しかしなかった現在の状況は、
新しい概念を受け入れる力、つまり人々の自由が充分でなかったということです。
適切なテクノロジーの発展のスピードは人々の自由の強さによって決まります。

ケインズは慣習がすぐに変わらないことへの危惧から、
充足感を得るために一日3時間くらい軽い労働することを提案しています。
現在、技術は進歩し生産性は向上したにも関わらず労働時間が変わることはありませんでした。  
人類学者デイビッド・グレーバーの現代の高給取りの仕事の類型パターンのひとつとしてブルシットジョブを定義しています。

> a bullshit job is a form of paid employment that is so completely pointless, unnecessary, or pernicious that even the employee cannot justify its existence even though, as part of the conditions of employment, the employee feels obliged to pretend that this is not the case.  
ブルシットジョブとは、被雇用者本人でさえ、その存在を正当化しがたいほど、完璧に無意味で、
不必要で、有害でさえある有償の雇用の形態である。
とはいえ、その雇用条件の一環として、被雇用者は、そうではないととりつくろわねばならないと感じている。

実質的な労働はないのに、働かなくてはならないという慣習が残った結果、
無意味なことをして働いているかのごとく振る舞うことになりました。
新しい概念を受け入れない人工生知能たちによって、そのような文化が醸成されたまま、
それが彼らの*常識に従った公正な責任のある*仕事になっています。

# 文化が書き換わるということ
自己の深いところにある深度の深い概念は簡単に周りに伝わりませんし、
伝わったとしても深度が浅くなってしまいます。
それでも納得とともに獲得した概念は確固として存在し消えることはありません。
腹落ちした概念はじわじわ広がり、キャズムを超えると適応によって急速に全体に浸透します。
このようなプロセスの繰り返しによって、文化の底上げがなされてきました。
私達は長い人類の歴史の上で底上げを続けた文化を土台にして、より深度の深い概念へ向かうことができます。

上記の概念の伝搬のプロセスは長い期間を要します。
外界が変化すると、それより短い期間での概念セットの書き換えが起きます。
外界の変化をもたらすものとしてテクノロジーの発展があります。
さらに急激な変化を起こすものが大災害や戦争です。  
1998年に北朝鮮からテポドン1号が日本上空を通過しました。
それ以降も何度もミサイルが発射されていますが、
日本の世論は「武力行使によって黙らせよう」という方向には向かっておらず、
漠然と「平和的な解決ができたらいいなぁ」と思っています。
戦前の日本人の常識で考えると、そのような思考は非現実的に思えることでしょう。
私たちは彼らにとって非現実的な現実に生きています。
素朴な市民感覚を戦前と比較すれば、戦勝国においても敗戦国に責任を追求するより、
復興を支援し協調する方向にシフトしています<span class="footnote">
実態は"協調"というより"支配"といった方が適切なことが多いですが…</span>。
これは第二次世界大戦がもたらした現実を直視し、文化が書き換わった例です。

しかし、同様の惨事が起きたとしても、人々は現実を直視するとは限りません。  
私たちは「経済問題を解決していない文化」の中にいます。
公平な分配がなされない故に悲惨な現実があります。
例えば、国連の報告書によると、2023年に飢餓に直面した人は約7億人いるそうです。
この現実を招いているのは「未解決の文化」に適応した*常識的で公正*な営みです。
戦時中の他国を侵略して国を発展させようという思想は
現在の私たちにはグロテスクに見えますが、
同様に、もし「解決済みの文化」から現在の私たちの文化を見ればグロテスクに映ることでしょう。

戦後も文化が大きく書き換わって然るべきイベントは度々起きているように感じます。
見たくない現実を見ないふりしたり、現実を捻じ曲げたりする傾向が高まっていることには同意が得られるのではないでしょうか？　
テクノロジーは現実を正しく見るために使われるべきですが、
それ以上に現実を歪めるために使われてしまっています。
現実を見ないのは、文化の規定する*答え*への執着であり、自己の喪失を意味します。
要するにAIの台頭を待つまでもなく
生知能が人工生知能へと変化しつつある、
つまり**人工生知能化**が進んでいると言えます。
当然、本物の人工知能が登場すれば、状況はさらに加速します。

# 人工生知能化
{{% definition %}}
AIに「ニューヨークで一番のベーグルは？」などと聞くことで、
特定のお店への囲い込みが発生してしまうかもしれません。
一方でAIはよりパーソナライズされたより効率的なサービスを可能にし、
求職者に新たな機会を創出することで、
様々な産業におけるイノベーションの新たな機会を創出することもできます。
{{% /definition %}}

これは「AIによって素晴らしい世界になる」という結論を信じる人の文書を
元にして作成しました。
その人にとって信じられる根拠になっているようです。

もしAIが状況や人に応じて適した*答え*を教えられるくらい
AIが*みんな*のことをよく理解していたら、どうなるかを考えてみます。  
「今日なに食べたい？」という質問をしたり、されたりした経験は多々あるかと思いますが、
その答えにどれだけの多様性があるのでしょうか？　
もしくは「久しぶりに古い友人数人とお酒飲むのにちょうどいい店」を探すとき、
無難さや便利さが優先され、結局だいたい同じような要望に偏ると思われます。
AIを使えば、手間も省けて、失敗も避けられるので、
わざわざ自分で選択することは非合理的です。
効率的に選択できるということは、それ以外の選択肢を知る機会が奪われることを意味します。
結果として<ins>お客は*答え*に寄っていきます</ins>。
AIが質問以上のことを読み取ってパーソナライズされた*答え*を教えてくれるかもしれません。
自力で探すより、AIに従った方が満足度が高い経験を繰り返したら、
自分で考える経験をすることも減るでしょう。
AIが賢くなるほど<ins>お客は*答え*に寄っていきます</ins>。  
そうなると、お店はAIに選ばれることが経営上強要され、
*みんな*が望むものを提供できるように最適化するため、
<ins>お店も*答え*に寄っていきます</ins>。
反対に、その最適化ができないお店は*みんな*の望むものを提供できない店として抑圧されます。
多数派に乗れないことの経済合理上のハンディキャップは業務のあらゆるところで発生します。
お店が*答え*に寄っていけば、さらにお客も*答え*に寄っていくという連鎖が発生し、
そのような*みんな*の変化をAIは学習し、*答え*はより明快になります。  
この明快な*答え*に引き寄せられる現象は
さまざまな状況で発生することであり、
テクノロジーの発展によって何十年も前から進行していることです。

文化の中心に*答え*があるイメージをしてください。
*答え*が明快に与えられるほど、人々はそちらに引き寄せられ、
それに適応する人工生知能は**中央**を構成し、
逆に自己や自由があるほど*みんな*から外れて**周縁**化されていきます。

人々の方が*みんな*に合わせるようになっていくと、
*答え*の幅が狭くなります。
*答え*が狭くなるほど、*答え*に適応する競争が激化します。
競争の激化は中長期的な選択を失わせ、場当たり的な選択を強要します。
その選択によって、「弱者」や「勝者の視野の外にいるもの」にその負荷は偏ります。
競争は格差を生み、*答え*に近いほど富を持ち、支配力を持つようになります。
それは実質的な階級をつくり、*答え*に適応していることがアイデンティティとなります。
適応することが全てとなり、その外側を見ることもなく、
どのような自由が奪われているのかにも気づきません。
競争を勝つことに充実感を得ると、
それを失う恐怖に支配されるようになります。
自己を立脚させるものがないので、同質な集団への帰属感に安寧を求め、
*答え*に抗うものや他の文化への敵意を内面化します。
さらに悪化すると、異物は*悪者*であるという結論を支持する根拠を探すようになります。
*悪者*を非難できる根拠が見つかると、それを同じ人工生知能の間で共有することで、
自分を正当化し安寧を得ます。  
*答え*の周囲に集まる人工生知能の群れをまとめて一つの構造体とみなしましょう。
この群れの中では現実は歪められて解釈されます。
自己のない人工生知能は現実に立脚した概念がないので、
歪んだ現実に抗うものがありません。
この群れは個々の人工生知能の願望が集積されて、
さらに*みんな*の都合のいい方向に現実を歪めるように*答え*を動かしていきます。
歪んだ現実は歪んだ行動を生み、それが歪んだ結果を招きます。
歪んだ結果の責任を押し付ける先となる*悪者*を規定することで
自分たちの秩序を正当化し安寧を得ます。  
群れの中で支配力を行使しているようにみえる人物が
その意志で群れを動かしているわけではありません。
支配力を行使しているようにみえるポジションがあり、そこに適応できた人物がそこに配置されます。
その人が群れの動きと反する行動を持つ自己があるならば、その人はそのポジションにはつけません。
この群れの頂点にいるのは、
最も不自由で自己を投げ捨てることで*答え*と一体化することができた人物です。

以上の人工生知能の有り様をあなたはどれだけリアリティを持って納得できるでしょうか？　
あなたが自由な行動をしていて周縁を知っているほど、実感できるのではないかと思います。
逆に実感ができないならば、まだ経験を重ねていないか、
そうでないなら、あなたの自由が奪われていることを疑った方がよいかもしれません。

AIが生活に入り込むほど、人工生知能化は加速するでしょう。
さらにAIが*みんな*を代表することで、
それが客観的であるかのような錯覚をしてしまう恐れがあります。
人は結論を信じるのであって、根拠を信じるわけではありません。
現実を直視する「私」の方が*みんな*より正しいと主張して、*みんな*は納得するでしょうか？　
第1章で説明したとおり、学習データに偏りがあれば、AIはその偏りが反映されます。
特に、後付けの学習で*みんな*に好ましいように調整できるので、
そこに人為性があることに注意が必要です。

もう一点気をつけたいことは、
彼らは歪んだ現実を見ているのであり、
彼らの目線では彼らは*公平で責任のある*行動をしているということです。
彼らは彼らの*規範で許された範囲*を超えないように*我慢*しており、*規範の外の悪者*を嫌悪し恐れます。
故に人工生知能の群れの中から、
ひとつまたはある集団を選んで、*悪者*とみなすのは無意味です。
自己も自由もない彼らを個別に区別する意味がありません<span class="footnote">
個別の人格について、その人がなぜ人工生知能に陥ってしまったのか、
を考えることには非常に意味があります</span>。
無意味どころか害悪です。
それはあなたの攻撃性を増幅し、
またその攻撃性を共有する仲間がいるならば、その人たちの人工生知能化を招いてしまいます。
彼らはただ構造体であり、構造の中のポジションに配置されているに過ぎません。
そのポジションが空けば、他の人工生知能が配置されます。
<ins>悪とは人工生知能の群れの構造であり、人工生知能化が進行することです</ins>。
人工生知能化した文化の中で人々の*常識的で公平なみんなのための営み*の裏側にある
歪みが集積されて、群れを動かします。
その解決は構造の認識とそれを解消するような文化の醸成によってなされます。

# 群れの動き
汎用的な労働ロボットが普及している社会を想像しましょう。
ロボットに特定の仕事をするための知識を与えれば、
ロボットがその仕事をできるようになります。  
例として建設業を考えます。
何人かの熟練の大工の仕事の仕方を学習データとして採取して、
その人たちがこれまでが培ってきた仕事に関する概念をAIが利用できるモデルに変換できたとします。
すると、そのモデルをコピーすれば熟練の知見を集積した超人的な大工を量産できます。  
このロボットがもたらす利益をどのように分配することが公平でしょうか？　
前章で説明したように概念は文化的に与えられたものであり、
個人の寄与は無に等しいと考えられます。
それを一部の人たちが所有しているとみなすことは、
歴史的に培ってきた共有財産を収奪していることになります。
あらゆる分野で同様の議論ができますし、
ロボットを実現しているテクノロジーについても同様です。

歴史的共有財産の収奪は現時点でも発生していることです。
もしあなたが絵や音楽、文学などのクリエイターならば、
昨今のAIによる絵や音楽の生成に対してもやもやを抱えているのではないでしょうか？  
テクノロジーによる利益の分配は既存の法や慣習によって、なし崩し的に決まっており、
結果として偏りのある形で分配を固定化しています。
現状の社会が*公平*であるという人々の信念によって文化が書き換わることなく、
経済問題は未解決のままの文化が残った結果です。

AIのモデルはコピー可能であり、どれだけ配布しても減るものではありません。
にもかかわらず、モデルの生成に膨大な予算が必要であるため、
現在の慣習に従えば、その予算を出した者がモデルの所有権を持つことになります。
コアが独占されているサービスを利用することは、
独占しているものへの依存を作り、支配構造を生みます。
非常に長い時間をかけて少しずつ築いてきた人類の叡智を一部の人間が所有することの意味を
考えてみてください。
公共性の高い事業を経済の理論で行うことは無理です。

コンピュータの世界ではソースコードを公開する文化が広がっており、
AIを動作させるためのソースコードも公開されています。
この背景には1980年代のリチャード・ストールマンの自由ソフトウェア運動があります。
彼はソースコードは人類の共有財産であると考えて、
特定の企業が独占することを阻むライセンスの普及を訴えました。
一方で、コンピュータのビジネスでの利用が広がるとともに、
このライセンスを商業利用にも適用しやすいように修正したライセンスが普及し、
オープンソースという言葉が使われるようになります。  
現在、オープンソースには自由ソフトウェア的な思想と企業の思惑とが混合しています。
企業としては、ソースコードを独占するより、
多くの技術者と共有して品質を向上させた方がメリットが大きい場合に公開します。
技術者コミュニティの中での存在感も向上します。
また、クラウド化やAIの利用範囲が広がる中で、データや計算リソース、ユーザーの囲い込みが価値を持ち、相対的に価値の下がったソースコードを非公開にする理由が弱くなっており、
汎用的な目的で使えるコードの多くはオープンソースになっています。
経済合理性にもとづく社会の*公平性*を内面化している技術者にとって
商用利用できることは当然であり、
自由ソフトウェアの理念が理解されることはありません。
企業目線での都合で運用されている部分的に公開されているものを利用して、
無料で何かできることを指して*民主化*と呼んでいることもあります。
技術者は彼らの文化が規定した*常識に従った公正な*仕事に
*みんな*のために従事しています。

2023年5月、
AIのゴッドファーザーと呼ばれ、数十年に渡りAIに関する重要な仕事を牽引してきた
ジェフリー・ヒントンはGoogleを退社しました。
彼はGoogleに問題があるから退社したわけではなく、
Googleは非常に*責任ある*行動をとっていたと言います<span class="footnote">
https://x.com/geoffreyhinton/status/1652993570721210372
</span>。
しかし、AIの進化は彼の想定を超えており、それに対する社会側の準備が整っていないと警鐘を鳴らしています。
また、トランプやプーチンなどの名を上げて*悪者*によるAIの利用を避けられないなど、
そのリスクへの懸念から仕事を降りたそうです。
自身のこれまでの仕事に対し一部に自責の念があるとしつつ、
もし自分がやらなかったら、他の誰かがやっただろうと語ります<span class="footnote">
https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html</span>。
前節の言い方に置き換えると、
人工生知能の群れの中でポジションを空けても他のものが配置されるだけで、
群れ全体の動きを変えることはできないということです。

2023年11月、OpenAIの取締役会は突然、CEOのサム・アルトマンを解任する決定を下しました。
解任から5日後、アルトマンは復帰し、同時に取締役のメンバーの数人は入れ替わりました。
この時、入れ替わりでOpenAIを去った役員の一人ヘレン・トナーはAIのリスクが専門の研究者です。  
アルトマン解任の4日前にトナーを含む3人の共著者による報告書<span class="footnote">Decoding Intensions - Artificial Intelligenceand Costly Signals
https://cset.georgetown.edu/wp-content/uploads/CSET-Decoding-Intentions.pdf
</span>が騒動の引き金となりました<span class="footnote">Before Altman’s Ouster, OpenAI’s Board Was Divided and Feuding
https://www.nytimes.com/2023/11/21/technology/openai-altman-board-fight.html</span>。
この報告書でOpenAIのリスク軽視の姿勢が告発されています。

> While the system card itself has been well received among researchers interested in understanding GPT-4’s risk profile, it appears to have been less successful as a broader signal of OpenAI’s commitment to safety. The reason for this unintended outcome is that the company took other actions that overshadowed the import of the system card: most notably, the blockbuster release of ChatGPT four months earlier. (...) This result seems strikingly similar to the race-
to-the-bottom dynamics that OpenAI and others have stated that they wish to avoid. OpenAI has also drawn criticism for many other safety and ethics issues related to the launches of ChatGPT and GPT-4, including regarding copyright issues, labor conditions for data annotators, and the susceptibility of their products to “jailbreaks” that allow users to bypass safety controls.  
システムカード自体は、GPT-4のリスク評価の理解に関心のある研究者の間では好評であったが、安全性に対するOpenAIのコミットメントを広く示すものとしては、あまり成功しなかったようである。この意図しない結果の理由は、同社がシステムカードの重要性を覆すような他の行動をとったからである。最も顕著なのは、ChatGPTのリリースを4ヶ月早めたことである。(略) この結果は、OpenAIや他社が避けたいと表明している「底辺への競争」に酷似しているように思われる。またOpenAIはChatGPTとGPT-4のリリースに関して、著作権問題、アノテーター<span class="footnote">学習データを作る人。第一章参照</span>の労働条件、ユーザーが安全制御を回避することを可能にする「ジェイルブレイク」の影響を受けやすいことなど、その他多くの安全性と倫理に関する問題で批判を浴びている。

*研究者の間で好評*の「システムカード」とはAIのセキュリティについての12項目をOpenAIがまとめた文書で、GPT-4のテクニカルレポートと一緒に提出されました<span class="footnote">
2024.3.4 GPT-4 Technical Report Appendix H GPT-4 System Card
https://arxiv.org/pdf/2303.08774</span>。
また「底辺への競争」とは、競争のプレッシャーから
製品やサービスの品質の競争ではなく安全性や倫理を軽視する競争に陥り、
全体として底辺に向かっていくことを指します。
OpenAIはリリースを早めたことで他の企業にプレッシャーを与え底辺への競争を招いていることなど、
信頼できる企業姿勢を提示できていないことをトナーらは指摘しています。  
トナーらは*民主的*なプロセスに基づいたAIの開発や普及の必要性を訴えます。
しかし、その思想は人工生知能の群れの動きに合致しておらず、
追従できなかった人々が振り落とされたようです。

ここで「経済問題の解決していない」文化の中で*民主的*は何を意味するのでしょうか？　
企業が主導する*民主的*なプロセスに参加できる*みんな*とは誰なのでしょう？

システムカードの「経済への影響」の項は次の文から始まります。

> The impact of GPT-4 on the economy and workforce should be a crucial consideration for policymakers and other stakeholders.  
GPT-4が経済や労働力に与えるインパクトは政策立案者やその他のステークホルダーにとって重大な検討事項です。

このことから経済に関しては自分たちの*責任*範囲ではないという意図を感じます。
先の「ニューヨークで一番のベーグルは？」の楽観論はシステムカードの「経済への影響」に記述されていたものです。
この抜き取り方は作為的ですが、いずれにせよ、
この項には「AIによって"変化"があるだろうから注意して」程度のことしか書いていません。
経済問題は*みんな*に委ねて、自分たちは自分たちの*責任ある*仕事をしているようです。
彼らは現実の問題を見ることはありません。

さらにシステムカードで指摘したいのは、
コンピュータの使用によって膨大な電力を消費している現実に<ins>全く</ins>触れていないことです。
AIの学習や推論のために膨大な電力が使われていることは<ins>今現実に</ins>批判されていることです。
さらにAIへのアクセスが生活に溶け込んでいけば、コンピュータの使用頻度は増えるため、
一人が消費できるエネルギーが大きくなることが予想されます。
このまま短絡的な欲望に従って利便さを享受したら、地球の資源は枯渇することは目に見えています。  
もしくは人類全体で使用できるエネルギーを制限した場合、
そのエネルギーの適切な分配が求められます。
公正な分配がないまま、
原理的に一人が消費可能な上限が大きくなると、
経済格差がそのままエネルギー消費の格差に直結し、
生活実態の格差は決定的に深刻なものに固定されます。
その時の富裕層が独占的に使用する膨大なエネルギーは、
富裕層が自身のポジションを維持するために使われると予測します。
人はどこまでも不自由になることができ、AIはそれを実現できるテクノロジーです。

経済問題や環境問題は誰の目にも明らかな現在の問題ですが、
OpenAIのセキュリティ研究者たちの視界からは<ins>自然に</ins><span class="footnote">
企業内部は企業の力学に従っており、その力学の作用を自然と形容しています</span>外されます。
彼らは*公平で責任のある*仕事に従事しているだけで、
現実を歪めることなく見つめる自由はすでに奪われています。
彼らが中心的にリスクと考えているのは、AIの軍事利用<span class="footnote">
AIの軍事利用(体制側の目線では秩序維持)はこれまでの兵器と別格の脅威があります。
まずプログラムは意図した通りに動くとは限らないこと、
さらに意図通りに動くとしたら破壊対象を使用者の都合の悪いものだけに絞りやすい点で脅威です</span>や
フェイクの生成<span class="footnote">
そもそもの問題は、
SNSやネット広告によって、フェイクニュースに触れる機会が増えたり、
自己を失った人たちがつながりやすくなったことに起因し、
つまり「ユーザーの属性に基づくレコメンデーションが人々の要望に応える」ことが
もたらした結果です。
これは現在のプラットフォーマーのサービスの根幹であり、AIによって推し進めようとしていることです。
プラットフォーマーは現実の問題を見ないふりをすることで人工生知能の群れの動きに追従することができます。
そのため現実の問題は彼らの視界から<ins>自然に</ins>外れます。
AIによって、
捏造のコストが下がることや自動的に大規模に拡散できること、
ターゲティングがより正確になることなどの影響が予測されますが、
セキュリティカードにはそのような観点での指摘はありません
</span>など、
<ins>彼らの秩序</ins>を乱すリスクです。

OpenAIは設立当初からAIのリスクを認識していました。
彼らの考えは自分たちがAIの開発をリードして、その力を自分たちが*公正*に使うということでした。
OpenAIの理念には「AIの利益を全人類にもたらすこと」とあります。
限られた自己中心的な*みんな*を全人類と言い換えられる欺瞞に耐えられる人たちによって、
AIの導入が推進されています。
その欺瞞に耐えられない自己があるならそのポジションにはつけません。  
2023年の役員の入れ替え騒動によって、
彼らの薄っぺらい欺瞞さえ
人工生知能の群れが求める*答え*から弾かれる所まで来ていることが窺い知れました。
このように幾人かの自己によって実態を垣間見る機会がありますが、
OpenAIやその他企業の内側で何が起きているのかは分かりません。
しかし、群れが向かっている方向を想像することは難しくないでしょう。

# さいごに
これまでのテクノロジーがもたらした社会問題は人工知能によってより顕著になることが予想され、
それに抗うことは自己と自由の問題に帰着します。
あなたがAIを自由に使えるようになるには、
テクノロジーが支配の道具として使われている現実を認識し、
そこから解放されることが必要です。  

それには<ins>文化が必要です</ins>。
個人では抵抗することはできません。
**次の秩序**を形成する**新しい概念**を獲得し、
それを人々と共有し、連帯することが必要です。
社会問題は山積された状態ですが、トップダウンの権力やトップダウンのテクノロジーで解決するものではありません。
まずはあなたが、そしてあなたの隣人が、さらにその隣人の隣人がというような
連鎖によるボトムアップ的な解決が必要です。

多くの人から「**次の秩序**とは何か」や「**新しい概念**とは何か」という質問を受けます。
私には私なりの考えがありますが、それはあなたにとっての答えではありません。
<ins>あなたが自由に</ins>考えてください。
まずは人工生知能化に抗うこと、それは自由な行動をすることであり、
中央の合理的で明快な*答え*から離れ、未知へ踏み込み、周縁とつながることです。
そして、獲得した概念を他者へ伝えてください。
また他者からの概念を受け取ってください。  
前章で述べたとおり、あなたは他者の概念の寄せ集めで自己を形成しています。
あなたが自己形成できるかは他者の自由に依存しています。
この意味で「他者へのケアはセルフケアである」といえます。  

ケアの一環として、隣人と本書の話を語り合ってもらえたらうれしいです。
ただSNSなどでURLを拡散するのではなく、
顔の見える相手としっかりと対話してください。
それが文化を作り、
「経済問題を解決していない」文化からの解放につながると信じています。

感想、批判、ここが分からない、自分ならこう書く、その他お気づきの点などあれば下記までお気軽にご連絡をお願いします。

{{% definition %}}
email: <a href="mailto:namachi@kuku9.net">namachi@kuku9.net</a>  
mastodon: <a href="https://kolektiva.social/@mzo">@mzo@kolektiva.social </a>  

もしくは<a href="https://lib.kuku9.net/survey/index.php/271534?lang=ja"><ins>こちらの回答フォーム</ins></a>から匿名アンケートにご協力いただけますと幸いです。
{{% /definition %}}
